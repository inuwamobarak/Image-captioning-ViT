{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install litserve"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eqt71bSS47kZ",
        "outputId": "c54669a8-677e-45cc-9ba4-0fa5e3229454"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting litserve\n",
            "  Downloading litserve-0.2.3-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting fastapi>=0.100 (from litserve)\n",
            "  Downloading fastapi-0.115.2-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting httpx (from litserve)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting uvicorn>=0.29.0 (from uvicorn[standard]>=0.29.0->litserve)\n",
            "  Downloading uvicorn-0.31.1-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting starlette<0.41.0,>=0.37.2 (from fastapi>=0.100->litserve)\n",
            "  Downloading starlette-0.39.2-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.100->litserve) (2.9.2)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.100->litserve) (4.12.2)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.29.0->uvicorn[standard]>=0.29.0->litserve) (8.1.7)\n",
            "Collecting h11>=0.8 (from uvicorn>=0.29.0->uvicorn[standard]>=0.29.0->litserve)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.29.0->litserve)\n",
            "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting python-dotenv>=0.13 (from uvicorn[standard]>=0.29.0->litserve)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.29.0->litserve) (6.0.2)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.29.0->litserve)\n",
            "  Downloading uvloop-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.29.0->litserve)\n",
            "  Downloading watchfiles-0.24.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting websockets>=10.4 (from uvicorn[standard]>=0.29.0->litserve)\n",
            "  Downloading websockets-13.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->litserve) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->litserve) (2024.8.30)\n",
            "Collecting httpcore==1.* (from httpx->litserve)\n",
            "  Downloading httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->litserve) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->litserve) (1.3.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi>=0.100->litserve) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi>=0.100->litserve) (2.23.4)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->litserve) (1.2.2)\n",
            "Downloading litserve-0.2.3-py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.115.2-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.7/94.7 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.31.1-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading starlette-0.39.2-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvloop-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-0.24.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (425 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m425.7/425.7 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading websockets-13.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (164 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.1/164.1 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: websockets, uvloop, python-dotenv, httptools, h11, watchfiles, uvicorn, starlette, httpcore, httpx, fastapi, litserve\n",
            "Successfully installed fastapi-0.115.2 h11-0.14.0 httpcore-1.0.6 httptools-0.6.1 httpx-0.27.2 litserve-0.2.3 python-dotenv-1.0.1 starlette-0.39.2 uvicorn-0.31.1 uvloop-0.20.0 watchfiles-0.24.0 websockets-13.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xuVRF5eO4rXs",
        "outputId": "fef73128-2900-44b6-f668-d0542c9b4764"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Generated Caption: a man in a suit and hat standing in front of a building \n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import torch\n",
        "from PIL import Image\n",
        "from transformers import VisionEncoderDecoderModel, ViTImageProcessor, GPT2TokenizerFast\n",
        "import urllib.parse as parse\n",
        "import os\n",
        "\n",
        "# Verify URL function\n",
        "def check_url(string):\n",
        "    try:\n",
        "        result = parse.urlparse(string)\n",
        "        return all([result.scheme, result.netloc, result.path])\n",
        "    except:\n",
        "        return False\n",
        "\n",
        "# Load an image from a URL or local path\n",
        "def load_image(image_path):\n",
        "    if check_url(image_path):\n",
        "        return Image.open(requests.get(image_path, stream=True).raw)\n",
        "    elif os.path.exists(image_path):\n",
        "        return Image.open(image_path)\n",
        "    else:\n",
        "        raise ValueError(f\"Invalid image path: {image_path}\")\n",
        "\n",
        "# HuggingFace API class for image captioning with accelerator support\n",
        "class ImageCaptioningLitAPI:\n",
        "    def setup(self, **kwargs):\n",
        "        # Get parameters from kwargs with default values\n",
        "        accelerator = kwargs.get('accelerator', 'auto')\n",
        "        devices = kwargs.get('devices', 1)\n",
        "        workers_per_device = kwargs.get('workers_per_device', 1)\n",
        "\n",
        "        # Choose the device based on the accelerator input\n",
        "        if accelerator == \"cuda\" and torch.cuda.is_available():\n",
        "            self.device = \"cuda\"\n",
        "        else:\n",
        "            self.device = \"cpu\"\n",
        "\n",
        "        # If accelerator=\"auto\", auto-detect GPU or fallback to CPU\n",
        "        if accelerator == \"auto\":\n",
        "            self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "        print(f\"Using device: {self.device}\")\n",
        "\n",
        "        # Load the ViT Encoder-Decoder Model\n",
        "        model_name = \"nlpconnect/vit-gpt2-image-captioning\"\n",
        "        self.model = VisionEncoderDecoderModel.from_pretrained(model_name).to(self.device)\n",
        "\n",
        "        # Load the corresponding Tokenizer\n",
        "        self.tokenizer = GPT2TokenizerFast.from_pretrained(model_name)\n",
        "\n",
        "        # Load the Image Processor\n",
        "        self.image_processor = ViTImageProcessor.from_pretrained(model_name)\n",
        "\n",
        "    # Generate image caption\n",
        "    def predict(self, image_path):\n",
        "        image = load_image(image_path)\n",
        "\n",
        "        # Preprocessing the Image\n",
        "        img = self.image_processor(image, return_tensors=\"pt\").to(self.device)\n",
        "\n",
        "        # Generating captions\n",
        "        output = self.model.generate(**img)\n",
        "\n",
        "        # Decode the output to generate the caption\n",
        "        caption = self.tokenizer.batch_decode(output, skip_special_tokens=True)[0]\n",
        "\n",
        "        return caption\n",
        "\n",
        "# Instantiate the class and set up\n",
        "api = ImageCaptioningLitAPI()\n",
        "\n",
        "# Pass the accelerator and other parameters here\n",
        "api.setup(accelerator=\"cuda\", devices=1, workers_per_device=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 1\n",
        "image_path = \"/content/cbimage.png\"\n",
        "\n",
        "caption = api.predict(image_path)\n",
        "print(f\"Generated Caption: {caption}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8YC6vpXn6AHv",
        "outputId": "a041e789-ebba-4a0c-885a-0262de93f251"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Caption: a man in a suit and tie holding a red and white flag \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 3\n",
        "image_path = \"/content/image (2).png\"\n",
        "\n",
        "caption = api.predict(image_path)\n",
        "print(f\"Generated Caption: {caption}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_9zsKwQ6evr",
        "outputId": "bff30c91-370b-4c0e-94be-bcd16a2842ca"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Caption: a view from a boat of a beach with a large body of water \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WmOH06Xj6rUA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}